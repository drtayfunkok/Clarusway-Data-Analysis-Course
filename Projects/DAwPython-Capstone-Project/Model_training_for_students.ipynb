{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4UCsvzbImqZN"
   },
   "source": [
    "___\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV\" class=\"img-fluid\" alt=\"CLRSWY\"></p>\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.warn(\"this will not show\")\n",
    "\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"getdummied_autoscout_F1382-Heagle.txt\")\n",
    "# df.head()\n",
    "# df.to_csv('getdummied_autoscout.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_table('final_scout_dummy_F1329 - allen', delimiter = ',')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sample_file.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df = df.join(df[\"comfort_convenience\"].str.get_dummies(sep = \",\").add_prefix(\"cc_\"))\n",
    "df = df.join(df[\"entertainment_media\"].str.get_dummies(sep = \",\").add_prefix(\"em_\"))\n",
    "df = df.join(df[\"extras\"].str.get_dummies(sep = \",\").add_prefix(\"ex_\"))\n",
    "df = df.join(df[\"safety_security\"].str.get_dummies(sep = \",\").add_prefix(\"ss_\"))\n",
    "\n",
    "df.drop([\"comfort_convenience\",\"entertainment_media\",\"extras\",\"safety_security\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = pd.get_dummies(df, drop_first =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()*100 / df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(\"nr_of_doors\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.isnull().sum()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace([True, False], [1, 0], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QsEUUAAKmqZN"
   },
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-3gMQ3utmqZN"
   },
   "source": [
    "### Train | Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"price\", axis =1)\n",
    "y = df[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    print(df[i].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling and Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score \n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(actual, pred):\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    mse = mean_squared_error(actual, pred)\n",
    "    score = r2_score(actual, pred)\n",
    "    return print(\"r2_score:\", score, \"\\n\",\"mae:\", mae, \"\\n\",\"mse:\",mse, \"\\n\",\"rmse:\",rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val(y_train, y_train_pred, y_test, y_pred):\n",
    "    \n",
    "    scores = {\"train_set\": {\"R2\" : r2_score(y_train, y_train_pred),\n",
    "    \"mae\" : mean_absolute_error(y_train, y_train_pred),\n",
    "    \"mse\" : mean_squared_error(y_train, y_train_pred),                          \n",
    "    \"rmse\" : np.sqrt(mean_squared_error(y_train, y_train_pred))},\n",
    "    \n",
    "    \"test_set\": {\"R2\" : r2_score(y_test, y_pred),\n",
    "    \"mae\" : mean_absolute_error(y_test, y_pred),\n",
    "    \"mse\" : mean_squared_error(y_test, y_pred),\n",
    "    \"rmse\" : np.sqrt(mean_squared_error(y_test, y_pred))}}\n",
    "    \n",
    "    return pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "An_5ITcAmqZO"
   },
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln_model = LinearRegression()\n",
    "ln_model.fit(X_train_scaled, y_train)\n",
    "y_pred = ln_model.predict(X_test_scaled)\n",
    "y_train_pred = ln_model.predict(X_train_scaled)\n",
    "ln_r2 = r2_score(y_test, y_pred)\n",
    "ln_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "train_val(y_train, y_train_pred, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor(random_state=101)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred = rf_model.predict(X_test)\n",
    "y_train_pred = rf_model.predict(X_train)\n",
    "rf_r2 = r2_score(y_test, y_pred)\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "train_val(y_train, y_train_pred, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADABOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_model = AdaBoostRegressor(random_state=101)\n",
    "ada_model.fit(X_train, y_train)\n",
    "y_pred = ada_model.predict(X_test)\n",
    "y_train_pred = ada_model.predict(X_train)\n",
    "ada_r2 = r2_score(y_test, y_pred)\n",
    "ada_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "train_val(y_train, y_train_pred, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model = GradientBoostingRegressor(random_state=101)\n",
    "gb_model.fit(X_train, y_train)\n",
    "y_pred = gb_model.predict(X_test)\n",
    "y_train_pred = gb_model.predict(X_train)\n",
    "gb_r2 = r2_score(y_test, y_pred)\n",
    "gb_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "train_val(y_train, y_train_pred, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBRegressor(random_state=101)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "y_train_pred = xgb_model.predict(X_train)\n",
    "xgb_r2 = r2_score(y_test, y_pred)\n",
    "xgb_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "train_val(y_train, y_train_pred, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = pd.DataFrame({\"Model\": [\"LinReg\", \"RF\", \"ADABoost\", \"GBoosting\", \"XGBoost\"],\n",
    "                        \"r2_score\": [ln_r2, rf_r2, ada_r2, gb_r2, xgb_r2],\n",
    "                        \"RMSE\": [ln_rmse, rf_rmse, ada_rmse, gb_rmse, xgb_rmse]})\n",
    "\n",
    "def labels(ax):\n",
    "    for p in ax.patches:\n",
    "        width = p.get_width()                        # get bar length\n",
    "        ax.text(width,                               # set the text at 1 unit right of the bar\n",
    "                p.get_y() + p.get_height() / 2,      # get Y coordinate + X coordinate / 2\n",
    "                '{:1.5f}'.format(width),             # set variable to display, 2 decimals\n",
    "                ha = 'left',                         # horizontal alignment\n",
    "                va = 'center')                       # vertical alignment\n",
    "    \n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.subplot(211)\n",
    "compare = compare.sort_values(by=\"r2_score\", ascending=False)\n",
    "ax=sns.barplot(x=\"r2_score\", y=\"Model\", data=compare, palette=\"Blues_d\")\n",
    "labels(ax)\n",
    "\n",
    "plt.subplot(212)\n",
    "compare = compare.sort_values(by=\"RMSE\", ascending=True)\n",
    "ax=sns.barplot(x=\"RMSE\", y=\"Model\", data=compare, palette=\"Blues_d\")\n",
    "labels(ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding The Best Modelling with Pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.regression import *\n",
    "\n",
    "s = setup(data=df, target='price', session_id=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Model training and selection\n",
    "\n",
    "best_model = compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost = create_model(\"xgboost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuned_xgboost = tune_model(xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_model(tuned_xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_model(tuned_xgboost, plot=\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_model = finalize_model(tuned_xgboost)\n",
    "# print(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV\" class=\"img-fluid\" alt=\"CLRSWY\"></p>\n",
    "\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "modeling_auto_scout_Student_V1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
